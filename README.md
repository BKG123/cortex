# Cortex

A **local-first conversation memory system** that ingests and stores conversation messages with vector embeddings for semantic search. Built with SQLite and FAISS for complete local operation.

## Features

- **Local-First Storage** ‚Äî All data stored locally using SQLite + FAISS
- **Semantic Search** ‚Äî Vector similarity search using sentence transformers
- **Multi-User Support** ‚Äî Organize conversations by user ID
- **Rich Metadata** ‚Äî Support for conversation grouping, roles, and custom metadata
- **Simple API** ‚Äî Clean Python interface with CLI tools

## Installation

### From PyPI (Recommended)

```bash
pip install cortex-memory
```

### From Source

```bash
# Clone the repository
git clone https://github.com/BKG123/cortex.git
cd cortex

# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install
pip install -e .
```

The sentence transformer model will be automatically downloaded on first use.

## Quick Start

```python
from memory.conversation import ConversationMemory, Message
from datetime import datetime
import uuid

# Initialize
memory = ConversationMemory()

# Add a message
message = Message(
    user_id="user123",
    message_id=str(uuid.uuid4()),
    content="Hello! I'm interested in machine learning.",
    role="user",
    timestamp=datetime.utcnow().isoformat()
)

memory.add_message(message)

# Search for similar messages
results = memory.search_similar("user123", "artificial intelligence", limit=5)
for msg, score in results:
    print(f"[{score:.3f}] {msg.content}")

memory.close()
```

## CLI Usage

```bash
# Add a message
cortex add user123 "Hello, how are you?" --role user

# Import conversation from JSON
cortex add-conversation user123 sample_conversation.json

# Retrieve messages
cortex get user123 --limit 10

# Semantic search
cortex search-similar user123 "machine learning" --limit 5

# Content search
cortex search-content user123 "AI" --limit 10

# View statistics
cortex stats user123
```

## API Reference

### ConversationMemory

Main interface for conversation storage and retrieval.

```python
memory = ConversationMemory(
    db_path="cortex.db",      # SQLite database path
    vector_dir="vectors"      # FAISS index directory
)
```

### Message Model

```python
@dataclass
class Message:
    user_id: str                    # User identifier
    message_id: str                 # Unique message ID
    content: str                    # Message content
    role: str                       # Message role (user, assistant, system)
    timestamp: str                  # ISO-8601 timestamp
    conversation_id: Optional[str]  # Optional conversation grouping
    metadata_json: Optional[str]    # JSON string for custom metadata
```

### Core Methods

```python
# Add messages
memory.add_message(message)
memory.add_messages([message1, message2])

# Search
memory.search_similar(user_id, query, limit=10)
memory.search_by_content(user_id, query, limit=50)

# Retrieve
memory.get_conversation(user_id, limit=100)
memory.get_conversation(user_id, conversation_id="conv_123")

# Analytics
memory.get_user_stats(user_id)

# Management
memory.delete_user_messages(user_id)
```

## Storage

- **SQLite**: Message metadata and relationships
- **FAISS**: Vector embeddings for semantic search
- **Sentence Transformers**: `all-MiniLM-L6-v2` model (384-dimensional embeddings)

All data is stored locally with no external dependencies or cloud services.

## Examples

See the included examples in the `examples/` folder:

```bash
# Basic demonstration
python examples/demo.py

# Comprehensive example
python examples/example_conversation.py

# Chat with OpenAI (requires API key)
export OPENAI_API_KEY="your-api-key-here"
python examples/chat_example.py


# Sample data
cortex add-conversation user456 examples/sample_conversation.json
cortex search-similar user456 "recommendation systems"
```

### Chat Example with OpenAI

The `examples/chat_example.py` demonstrates a complete chat interface using OpenAI and Cortex memory:

```python
from examples.chat_example import ChatBot

# Initialize chatbot
chatbot = ChatBot("user123")

# Chat with memory
response = chatbot.chat("Hello! What did we talk about yesterday?")
print(response)

# Search memory
results = chatbot.search_similar("machine learning")
for msg, score in results:
    print(f"[{score:.3f}] {msg.content}")

chatbot.close()
```

**Features:**
- ü§ñ Interactive chat with OpenAI GPT-3.5-turbo
- üß† Automatic conversation memory storage
- üîç Semantic search through conversation history
- üìù Context-aware responses using recent conversation
- üí¨ Commands: `context`, `search <query>`, `quit`

**Installation:**
```bash
pip install cortex-memory[chat]
# or
pip install cortex-memory openai
```

## Project Structure

```
cortex/
‚îú‚îÄ‚îÄ memory/
‚îÇ   ‚îú‚îÄ‚îÄ conversation.py    # Main conversation memory system
‚îÇ   ‚îú‚îÄ‚îÄ store.py          # SQLite storage layer
‚îÇ   ‚îî‚îÄ‚îÄ cli.py            # Command-line interface
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îú‚îÄ‚îÄ demo.py           # Basic demonstration
‚îÇ   ‚îú‚îÄ‚îÄ example_conversation.py # Comprehensive example
‚îÇ   ‚îú‚îÄ‚îÄ chat_example.py   # OpenAI integration example
‚îÇ   ‚îú‚îÄ‚îÄ test_chat_example.py # Test script for chat
‚îÇ   ‚îî‚îÄ‚îÄ sample_conversation.json # Sample data
‚îú‚îÄ‚îÄ pyproject.toml        # Project configuration
‚îî‚îÄ‚îÄ README.md            # Documentation
```

## Requirements

- Python 3.8+
- faiss-cpu>=1.7.4
- sentence-transformers>=2.2.2
- numpy>=1.24.0

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

MIT License - see [LICENSE](LICENSE) for details.
